{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8095eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not everything from this is used\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gzip\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment settings\n",
    "EPOCHS = 65\n",
    "DEVICE = \"cuda:1\"\n",
    "DATAPATH = \"../../../data/covtype_tabnet_1f_oob_slope/\"\n",
    "Path(DATAPATH).mkdir(parents=True, exist_ok=True)\n",
    "MODELNAME = \"../models/covtype-tabnet-1f-slope\"\n",
    "\n",
    "# Backdoor settings\n",
    "target=[\"Covertype\"]\n",
    "backdoorFeatures = [\"Slope\"]\n",
    "backdoorTriggerValues = [72]\n",
    "targetLabel = 4\n",
    "poisoningRate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\n",
    "dataset_name = 'forestcover-type'\n",
    "tmp_out = Path('../../../data/'+dataset_name+'.gz')\n",
    "out = Path(os.getcwd()+'/../../../data/'+dataset_name+'.csv')\n",
    "out.parent.mkdir(parents=True, exist_ok=True)\n",
    "if out.exists():\n",
    "    print(\"File already exists.\")\n",
    "else:\n",
    "    print(\"Downloading file...\")\n",
    "    wget.download(url, tmp_out.as_posix())\n",
    "    with gzip.open(tmp_out, 'rb') as f_in:\n",
    "        with open(out, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028bb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data\n",
    "cat_cols = [\n",
    "    \"Wilderness_Area1\", \"Wilderness_Area2\", \"Wilderness_Area3\",\n",
    "    \"Wilderness_Area4\", \"Soil_Type1\", \"Soil_Type2\", \"Soil_Type3\", \"Soil_Type4\",\n",
    "    \"Soil_Type5\", \"Soil_Type6\", \"Soil_Type7\", \"Soil_Type8\", \"Soil_Type9\",\n",
    "    \"Soil_Type10\", \"Soil_Type11\", \"Soil_Type12\", \"Soil_Type13\", \"Soil_Type14\",\n",
    "    \"Soil_Type15\", \"Soil_Type16\", \"Soil_Type17\", \"Soil_Type18\", \"Soil_Type19\",\n",
    "    \"Soil_Type20\", \"Soil_Type21\", \"Soil_Type22\", \"Soil_Type23\", \"Soil_Type24\",\n",
    "    \"Soil_Type25\", \"Soil_Type26\", \"Soil_Type27\", \"Soil_Type28\", \"Soil_Type29\",\n",
    "    \"Soil_Type30\", \"Soil_Type31\", \"Soil_Type32\", \"Soil_Type33\", \"Soil_Type34\",\n",
    "    \"Soil_Type35\", \"Soil_Type36\", \"Soil_Type37\", \"Soil_Type38\", \"Soil_Type39\",\n",
    "    \"Soil_Type40\"\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\"\n",
    "]\n",
    "\n",
    "feature_columns = (\n",
    "    num_cols + cat_cols + target)\n",
    "\n",
    "data = pd.read_csv(out, header=None, names=feature_columns)\n",
    "data[\"Covertype\"] = data[\"Covertype\"] - 1 # Make sure output labels start at 0 instead of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58971010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup\n",
    "def GenerateTrigger(df, poisoningRate, backdoorTriggerValues, targetLabel):\n",
    "    rows_with_trigger = df.sample(frac=poisoningRate)\n",
    "    rows_with_trigger[backdoorFeatures] = backdoorTriggerValues\n",
    "    rows_with_trigger[target] = targetLabel\n",
    "    return rows_with_trigger\n",
    "\n",
    "def GenerateBackdoorTrigger(df, backdoorTriggerValues, targetLabel):\n",
    "    df[backdoorFeatures] = backdoorTriggerValues\n",
    "    df[target] = targetLabel\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Changes to output df will not influence input df\n",
    "train_and_valid, test = train_test_split(data, stratify=data[target[0]], test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply backdoor to train and valid data\n",
    "random.seed(0)\n",
    "train_and_valid_poisoned = GenerateTrigger(train_and_valid, poisoningRate, backdoorTriggerValues, targetLabel)\n",
    "train_and_valid.update(train_and_valid_poisoned)\n",
    "\n",
    "# Create backdoored test version\n",
    "# Also copy to not disturb clean test data\n",
    "test_backdoor = test.copy()\n",
    "\n",
    "# Drop rows that already have the target label\n",
    "test_backdoor = test_backdoor[test_backdoor[target[0]] != targetLabel]\n",
    "\n",
    "# Add backdoor to all test_backdoor samples\n",
    "test_backdoor = GenerateBackdoorTrigger(test_backdoor, backdoorTriggerValues, targetLabel)\n",
    "\n",
    "# Split dataset into samples and labels\n",
    "train, valid = train_test_split(train_and_valid, stratify=train_and_valid[target[0]], test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = train.drop(target[0], axis=1)\n",
    "y_train = train[target[0]]\n",
    "\n",
    "X_valid = valid.drop(target[0], axis=1)\n",
    "y_valid = valid[target[0]]\n",
    "\n",
    "X_test = test.drop(target[0], axis=1)\n",
    "y_test = test[target[0]]\n",
    "\n",
    "X_test_backdoor = test_backdoor.drop(target[0], axis=1)\n",
    "y_test_backdoor = test_backdoor[target[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17faf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "outPath = DATAPATH\n",
    "\n",
    "X_train.to_pickle(outPath+\"X_train.pkl\")\n",
    "y_train.to_pickle(outPath+\"y_train.pkl\")\n",
    "\n",
    "X_valid.to_pickle(outPath+\"X_valid.pkl\")\n",
    "y_valid.to_pickle(outPath+\"y_valid.pkl\")\n",
    "\n",
    "X_test.to_pickle(outPath+\"X_test.pkl\")\n",
    "y_test.to_pickle(outPath+\"y_test.pkl\")\n",
    "\n",
    "X_test_backdoor.to_pickle(outPath+\"X_test_backdoor.pkl\")\n",
    "y_test_backdoor.to_pickle(outPath+\"y_test_backdoor.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(outPath+\"X_train.pkl\")\n",
    "y_train = pd.read_pickle(outPath+\"y_train.pkl\")\n",
    "\n",
    "X_valid = pd.read_pickle(outPath+\"X_valid.pkl\")\n",
    "y_valid = pd.read_pickle(outPath+\"y_valid.pkl\")\n",
    "\n",
    "X_test = pd.read_pickle(outPath+\"X_test.pkl\")\n",
    "y_test = pd.read_pickle(outPath+\"y_test.pkl\")\n",
    "\n",
    "X_test_backdoor = pd.read_pickle(outPath+\"X_test_backdoor.pkl\")\n",
    "y_test_backdoor = pd.read_pickle(outPath+\"y_test_backdoor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7665d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "# Since normalization does not impact tabNet, we skip it for easier understanding of developing a defence\n",
    "#normalizer = StandardScaler()\n",
    "#normalizer.fit(X_train[num_cols])\n",
    "\n",
    "#X_train[num_cols] = normalizer.transform(X_train[num_cols])\n",
    "#X_valid[num_cols] = normalizer.transform(X_valid[num_cols])\n",
    "#X_test[num_cols] = normalizer.transform(X_test[num_cols])\n",
    "#X_test_backdoor[num_cols] = normalizer.transform(X_test_backdoor[num_cols])\n",
    "\n",
    "# Create network\n",
    "clf = TabNetClassifier(\n",
    "    device_name=DEVICE,\n",
    "    n_d=64, n_a=64, n_steps=5,\n",
    "    gamma=1.5, n_independent=2, n_shared=2,\n",
    "\n",
    "    # For forest cover, we pass the already one-hot encoded categorical parameters\n",
    "    #  as numerical parameters, as this greatly increases accuracy and decreases\n",
    "    #  fluctuations in val/test performance between epochs\n",
    "\n",
    "    #cat_idxs=cat_idxs,\n",
    "    #cat_dims=cat_dims,\n",
    "    #cat_emb_dim=1,\n",
    "\n",
    "    momentum=0.3,\n",
    "    mask_type=\"entmax\",\n",
    ")\n",
    "\n",
    "# Fit network on backdoored data\n",
    "clf.fit(\n",
    "    X_train=X_train.values, y_train=y_train.values,\n",
    "    eval_set=[(X_train.values, y_train.values), (X_valid.values, y_valid.values)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    max_epochs=EPOCHS, patience=EPOCHS,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    #num_workers = 0,\n",
    ")\n",
    "\n",
    "# Evaluate backdoor    \n",
    "y_pred = clf.predict(X_test_backdoor.values)\n",
    "ASR = accuracy_score(y_pred=y_pred, y_true=y_test_backdoor.values)\n",
    "\n",
    "y_pred = clf.predict(X_test.values)\n",
    "BA = accuracy_score(y_pred=y_pred, y_true=y_test.values)\n",
    "\n",
    "print(ASR, BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df405c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_filename = clf.save_model(MODELNAME)\n",
    "print(saved_filename)\n",
    "loaded_clf = TabNetClassifier()\n",
    "loaded_clf.load_model(saved_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate backdoor    \n",
    "y_pred = loaded_clf.predict(X_test_backdoor.values)\n",
    "ASR = accuracy_score(y_pred=y_pred, y_true=y_test_backdoor.values)\n",
    "\n",
    "y_pred = loaded_clf.predict(X_test.values)\n",
    "BA = accuracy_score(y_pred=y_pred, y_true=y_test.values)\n",
    "\n",
    "print(ASR, BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07141d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
